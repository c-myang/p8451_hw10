---
title: "Machine Learning for Epidemiology: Assignment 10"
date: "April 4th, 2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      warning = F,
                      message = F,
                      fig.dim = c(12, 7))
```

In this exercise, we will use real-world exposomic data adapted from the HELIX harmonized birth cohorts in Europe to explore and develop a research question based on high-dimensional epidemiological data (HDD).

The exposomic data contains 4 data frames: exposome, phenotype, covariate and codebook. Exposome contains all of the environmental features measured on children. Phenotype contains health outcomes measured during the study. Covariate contains demographics and maternal information during pregnancy. Codebook is a detailed listing of all variables within the data frames. 

We will use these features to try to identify which pre-natal chemical exposures are the greatest risk factors for childhood neurobehavioural problems, as measured through the CBCL scale.

### Load .Rdata file and merge into single data frame

Below we will merge the exposome data, select the features related to pre-natal chemical exposures, select our phenotypic outcome of interest, `hs_Gen_Tot`, and partition the data into a 70/30 training-testing split.

```{r dataprep}
library(tidyverse)
library(caret)
library(rpart.plot)
library(kableExtra)

#Load data using path of where file is stored
load("./exposome.RData")

#Merge all data frames into a single data frame. 

studydata<-merge(exposome,phenotype,by="ID") %>% merge(covariates, by="ID")

#Strip off ID Variable
studydata$ID<-NULL

# Extracting features only related to pre-natal exposure to chemicals and neurobehavioural phenotype outcome
studydata = studydata %>% select(hs_as_m_Log2:hs_tl_mdich_None, hs_dde_madj_Log2:hs_cotinine_mcat_None, hs_Gen_Tot) %>% 
  select(contains(c("_m_", "_madj_", "e3_asmokcigd_p_None", "hs_cotinine_mcat_None", "hs_Gen_Tot")))

#Partition data
set.seed(123)
train.indices<-createDataPartition(y=studydata$hs_Gen_Tot, p=0.7, list=FALSE)
train.data<-studydata[train.indices, ]
test.data<-studydata[-train.indices, ]
```

### Step 1: Exploration of Training Data

The code chunk below outputs a table of summary statistics of the test data features. We will also plot the distribution of the outcome, the outcome, `hs_Gen_Tot`, to examine its overall distribution.

```{r dataexplore}
summary(train.data) %>% kbl(digits = 3) %>% 
  kable_classic(lightable_options = "hover") %>% 
  scroll_box(width = "100%", height = "100%")

ggplot(data = train.data, aes(x = hs_Gen_Tot)) + geom_histogram()
```
Based on the summary statistics, the log-transformed pre-natal chemical exposures have varying distributions across features, with features like arsenic levels (`hs_as_m_Log2`) , while the outcome appears to be right-skewed. 

### Step 2: Research Question

*What are the pre-natal exposures to chemicals (metals, Organochlorines, Organophosphate pesticides, PBDE, PFAS, Phenols, tobacco smoke) that best predict childhood neurobehavioural internalizing and externalizing problems (as measured on the CBCL scale)?*

***

### Step 3: Implement pipeline to address research question

For feature selection, we will use a LASSO algorithm to identify the features that best predict childhood internalizing/externalizing problems through the CBCL scale. The model will be trained using 10-fold cross-validation, with the alpha value fixed to 1 and using a search grid of 100 values between 10^(-0.5) and 10^(0.5) to tune lambda. The best tune will be selected based on the lowest RMSE. 

```{r algorithm}
set.seed(123)

#Create grid to search lambda
lambda = 10^seq(-0.5, 0.5, length = 100)

#Fit model with tuneGrid
mod_lasso = train(hs_Gen_Tot ~ ., data = train.data, method = "glmnet", 
                  trControl = trainControl("cv", number = 10), 
                  tuneGrid = expand.grid(alpha = 1, lambda = lambda),
                  preProcess = c("center", "scale"))

#Print the values of alpha and lambda that gave best prediction
mod_lasso$bestTune

mod_lasso$results %>% 
  arrange(RMSE) %>% 
  head(5) %>% 
  kbl(digits = 4) %>% 
  kable_classic("hover") 

coef(mod_lasso$finalModel, mod_lasso$bestTune$lambda) 

varImp(mod_lasso$finalModel) %>% arrange(desc(Overall)) %>% head(15)
```

The best tune for the LASSO model was found to be `r round(mod_lasso$bestTune$lambda, 3)`. Examining the coefficients in the model, we find that the number of exposure features shrank from 49 features to 14. The features of highest importance include pre-natal exposures to caesium (Cs), categorized levels of cotinine, molybdenum (Mo), lipid-adjusted DDE, and creatinine-adjusted BPA, respectively.

#### Final model evaluation

Finally, we will evaluate the performance our final LASSO model by making predictions in the test data. We will use the `postResample()` function to get performance measures of RMSE, R-squared, and MAE of the model on the test data.

```{r}
# Make predictions in test set
lasso_pred = mod_lasso %>% predict(test.data)
test.data = test.data %>% mutate(lasso_pred = lasso_pred)

# Model prediction performance
postResample(pred = lasso_pred, obs = test.data$hs_Gen_Tot) %>% 
  kbl(digits = 4) %>% 
  kable_classic("hover") 
```

The final model results in an RMSE of 16.82 and R-squared of 0.048. 

